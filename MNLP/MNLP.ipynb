{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b127d5e1-f86e-4280-809f-0762081b5fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys \n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "from base_trainer import Trainer\n",
    "from model import SimpleCNN\n",
    "from torch.utils.data import DataLoader, Subset, Dataset\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "06a6fe57-12bf-46b0-83bc-882a362e36bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T17:49:11.269491Z",
     "start_time": "2024-12-09T17:49:07.979060Z"
    }
   },
   "outputs": [],
   "source": [
    "class UpdatedTrainer(Trainer):\n",
    "    def calculate_mnlp(self, outputs, targets):\n",
    "        \"\"\"\n",
    "        Calculate Maximum Normalized Log-Probability (MNLP).\n",
    "        :param outputs: Model outputs (logits)\n",
    "        :param targets: True labels\n",
    "        :return: MNLP value\n",
    "        \"\"\"\n",
    "        probabilities = F.softmax(outputs, dim=1)\n",
    "        log_probabilities = torch.log(probabilities)\n",
    "\n",
    "        true_log_probs = log_probabilities[range(len(targets)), targets]\n",
    "        num_classes = probabilities.size(1)\n",
    "\n",
    "        # Normalize log probabilities\n",
    "        normalized_log_probs = true_log_probs / torch.log(torch.tensor(1.0 / num_classes).to(self.device))\n",
    "        return normalized_log_probs.mean().item()\n",
    "\n",
    "    def fit(self, num_epochs):\n",
    "        \"\"\"\n",
    "        Полный цикл обучения.\n",
    "        :param num_epochs: Количество эпох\n",
    "        \"\"\"\n",
    "        for epoch in range(num_epochs):\n",
    "            train_loss = self.train_step()\n",
    "            val_loss, accuracy, f1, avg_mnlp = self.val_step()\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Acc: {accuracy:.4f}, F1: {f1:.4f}, MNLP: {avg_mnlp:.4f}\")\n",
    "\n",
    "    def val_step(self):\n",
    "        \"\"\"\n",
    "        Один шаг валидации.\n",
    "        Вычисляет среднюю потерю, F1-score и точность.\n",
    "        :return: Средняя потеря, F1-score и точность за эпоху\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        running_loss = 0.0\n",
    "        all_targets = []\n",
    "        all_predictions = []\n",
    "        mnlp_values = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in tqdm(self.val_loader, desc=\"Validating\"):\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "\n",
    "                # Прямой проход\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, targets)\n",
    "\n",
    "                running_loss += loss.item()\n",
    "\n",
    "                # Сохранение предсказаний и истинных меток\n",
    "                predictions = outputs.argmax(dim=1).cpu().numpy()\n",
    "                all_predictions.extend(predictions)\n",
    "                all_targets.extend(targets.cpu().numpy())\n",
    "\n",
    "                # Сохранение MNLP\n",
    "                mnlp = self.calculate_mnlp(outputs, targets)\n",
    "                mnlp_values.append(mnlp)\n",
    "\n",
    "        # Рассчитываем метрики\n",
    "        avg_loss = running_loss / len(self.val_loader)\n",
    "        accuracy = accuracy_score(all_targets, all_predictions)\n",
    "        f1 = f1_score(all_targets, all_predictions, average=\"weighted\")\n",
    "        self.val_acc.append(accuracy)\n",
    "        self.val_f1.append(f1)\n",
    "\n",
    "        avg_mnlp = sum(mnlp_values) / len(mnlp_values) if mnlp_values else 0\n",
    "\n",
    "        self.val_losses.append(avg_loss)\n",
    "\n",
    "        print(f\"Validation Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}, F1 Score: {f1:.4f}, MNLP: {avg_mnlp:.4f}\")\n",
    "        return avg_loss, accuracy, f1, avg_mnlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "482be617-a32d-4bfc-b812-762882384e2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T17:49:35.539809Z",
     "start_time": "2024-12-09T17:49:30.591996Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Initial dataset (1%): 500\n",
      "Initial dataset (10%): 5000\n",
      "Initial dataset (20%): 10000\n",
      "Pool data size: 35656\n"
     ]
    }
   ],
   "source": [
    "NUM_CLASSES = 10           # CIFAR-10\n",
    "NUM_EPOCH = 10\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "percentages = [0.01, 0.10, 0.20]\n",
    "initial_datasets = {}\n",
    "pool_data_indices = []\n",
    "\n",
    "# Создаем словарь для хранения индексов по классам\n",
    "class_indices = defaultdict(list)\n",
    "\n",
    "# Заполняем словарь индексами изображений по классам\n",
    "for index, (_, label) in enumerate(train_dataset):\n",
    "    class_indices[label].append(index)\n",
    "\n",
    "# Формируем начальные наборы данных\n",
    "for percentage in percentages:\n",
    "    initial_indices = []\n",
    "    num_samples_per_class = {label: int(len(indices) * percentage) for label, indices in class_indices.items()}\n",
    "    \n",
    "    for label, indices in class_indices.items():\n",
    "        # Случайным образом выбираем индексы для каждого класса\n",
    "        selected_indices = np.random.choice(indices, num_samples_per_class[label], replace=False)\n",
    "        initial_indices.extend(selected_indices)\n",
    "    \n",
    "    # Сортируем индексы для создания подмножества\n",
    "    initial_datasets[percentage] = sorted(initial_indices)\n",
    "\n",
    "# Создаем pool_data с оставшимися данными\n",
    "all_initial_indices = set(initial_datasets[0.01] + initial_datasets[0.10] + initial_datasets[0.20])\n",
    "pool_data_indices = [i for i in range(len(train_dataset)) if i not in all_initial_indices]\n",
    "\n",
    "# Создаем подмножества для начальных данных и оставшихся данных\n",
    "initial_dataset_1_percent = torch.utils.data.Subset(train_dataset, initial_datasets[0.01])\n",
    "initial_dataset_10_percent = torch.utils.data.Subset(train_dataset, initial_datasets[0.10])\n",
    "initial_dataset_20_percent = torch.utils.data.Subset(train_dataset, initial_datasets[0.20])\n",
    "pool_data = torch.utils.data.Subset(train_dataset, pool_data_indices)\n",
    "\n",
    "# Проверяем размеры подмножеств\n",
    "print(f\"Initial dataset (1%): {len(initial_dataset_1_percent)}\")\n",
    "print(f\"Initial dataset (10%): {len(initial_dataset_10_percent)}\")\n",
    "print(f\"Initial dataset (20%): {len(initial_dataset_20_percent)}\")\n",
    "print(f\"Pool data size: {len(pool_data)}\")\n",
    "\n",
    "train_dataloader = DataLoader(initial_dataset_1_percent, batch_size=64, shuffle=True)\n",
    "pool_dataloader = DataLoader(pool_data, batch_size=64, shuffle=True)\n",
    "val_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=True)\n",
    "model = SimpleCNN(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b05e56b1-93dc-47bf-8775-4db5f7a701da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T17:49:40.518797Z",
     "start_time": "2024-12-09T17:49:40.417466Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(model.parameters(), lr=5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "train = UpdatedTrainer(model=model.to(DEVICE), optimizer=optimizer,criterion=criterion, train_loader=train_dataloader, val_loader=val_dataloader,pool_loader = pool_dataloader, device=DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3b088d2b53404b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "alidating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 157/157 [00:01<00:00, 149.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.2108, Accuracy: 0.2428, F1 Score: 0.1777, MNLP: 0.9601\n",
      "Epoch 1/2 - Train Loss: 2.2822, Val Loss: 2.2108, Acc: 0.2428, F1: 0.1777, MNLP: 0.9601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Validating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 157/157 [00:01<00:00, 149.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.0979, Accuracy: 0.2287, F1 Score: 0.1725, MNLP: 0.9111\n",
      "Epoch 2/2 - Train Loss: 2.1209, Val Loss: 2.0979, Acc: 0.2287, F1: 0.1725, MNLP: 0.9111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train.fit(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc941e93-7495-4e80-8f7a-831462890964",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
