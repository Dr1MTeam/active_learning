{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b127d5e1-f86e-4280-809f-0762081b5fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys \n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "from base_trainer import Trainer\n",
    "from model import SimpleCNN\n",
    "from torch.utils.data import DataLoader, Subset, Dataset\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "06a6fe57-12bf-46b0-83bc-882a362e36bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T17:49:11.269491Z",
     "start_time": "2024-12-09T17:49:07.979060Z"
    }
   },
   "outputs": [],
   "source": [
    "class MNLPTrainer(Trainer):\n",
    "    def select_samples(self):\n",
    "        self.model.eval()  # Set the model to evaluation mode\n",
    "        all_scores = []  # List to store MNLP scores for each sample\n",
    "        all_indices = []  # List to store indices of the samples\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in self.pool_loader:\n",
    "                inputs, indices = batch  # Assume loader returns data and their indices\n",
    "                inputs = inputs.to(self.device)\n",
    "\n",
    "                log_probs = torch.log_softmax(self.model(inputs), dim=-1)  # (batch_size, seq_len, num_classes)\n",
    "\n",
    "                # Для каждого примера суммируем логарифмы вероятностей по длине последовательности\n",
    "                sequence_log_probs = log_probs.sum(dim=-1)  # (batch_size, seq_len)\n",
    "\n",
    "                # Усредняем значения логарифмов вероятностей по длине последовательности\n",
    "                mean_log_probs = sequence_log_probs.mean(axis=0)  # (batch_size)\n",
    "\n",
    "                # Нормализуем логарифмы вероятностей по длине последовательности\n",
    "                normalized_log_probs = mean_log_probs / inputs.shape[1]  # (batch_size)\n",
    "\n",
    "                # Save results\n",
    "                all_scores.append(normalized_log_probs.cpu())\n",
    "                all_indices.append(indices)\n",
    "        \n",
    "        print(all_scores)\n",
    "\n",
    "        # Combine results across all batches\n",
    "        all_scores = torch.stack(all_scores) # All MNLP scores\n",
    "        all_indices = torch.cat(all_indices)  # All indices\n",
    "\n",
    "        # Select top-K indices with the lowest MNLP scores (most uncertain samples)\n",
    "        _, top_indices = torch.topk(-all_scores, 10)  # Negative for ascending sort\n",
    "        informative_indices = all_indices[top_indices].tolist()\n",
    "\n",
    "        # Update dataloaders for the next iteration\n",
    "        self.update_dataloader(informative_indices)\n",
    "\n",
    "        return informative_indices\n",
    "\n",
    "    def fit(self, num_epochs):\n",
    "        \"\"\"\n",
    "        Полный цикл обучения.\n",
    "        :param num_epochs: Количество эпох\n",
    "        \"\"\"\n",
    "        for epoch in range(num_epochs):\n",
    "            train_loss = self.train_step()\n",
    "            self.select_samples()\n",
    "            val_loss, accuracy, f1  = self.val_step()\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Acc: {accuracy:.4f}, F1: {f1:.4f}\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "482be617-a32d-4bfc-b812-762882384e2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T17:49:35.539809Z",
     "start_time": "2024-12-09T17:49:30.591996Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "NUM_CLASSES = 10           # CIFAR-10\n",
    "NUM_EPOCH = 10\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "percentages = [0.01, 0.10, 0.20]\n",
    "initial_datasets = {}\n",
    "pool_data_indices = []\n",
    "config = {}\n",
    "config['split_label_unlabel'] = 0.1\n",
    "config['batch_size']=64\n",
    "\n",
    "initial_indices = np.random.choice(len(train_dataset), size=int(len(train_dataset)*config['split_label_unlabel']), replace=False) # 20%\n",
    "initial_data = Subset(train_dataset, initial_indices)\n",
    "\n",
    "unlabeled_indices = list(set(range(len(train_dataset))) - set(initial_indices))\n",
    "unlabeled_data = Subset(train_dataset, unlabeled_indices)\n",
    "\n",
    "train_dataloader = DataLoader(initial_data, batch_size=config['batch_size'], shuffle=True)\n",
    "val_dataloader = DataLoader(test_dataset, batch_size=config['batch_size'], shuffle=True)\n",
    "pool_dataloader = DataLoader(unlabeled_data, batch_size=config['batch_size'], shuffle=True)\n",
    "\n",
    "model = SimpleCNN(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b05e56b1-93dc-47bf-8775-4db5f7a701da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T17:49:40.518797Z",
     "start_time": "2024-12-09T17:49:40.417466Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(model.parameters(), lr=5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "train = MNLPTrainer(model=model.to(DEVICE), optimizer=optimizer,criterion=criterion, train_loader=train_dataloader, val_loader=val_dataloader,pool_loader = pool_dataloader, device=DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3b088d2b53404b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 79/79 [00:06<00:00, 12.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(-14.4505), tensor(-14.0875), tensor(-14.7053), tensor(-14.1767), tensor(-14.4621), tensor(-14.1969), tensor(-14.3411), tensor(-14.9397), tensor(-13.8649), tensor(-13.8257), tensor(-14.8641), tensor(-14.7586), tensor(-14.1145), tensor(-13.9136), tensor(-14.3768), tensor(-13.5882), tensor(-13.9425), tensor(-14.2765), tensor(-14.0406), tensor(-14.7136), tensor(-13.3104), tensor(-14.3849), tensor(-14.5428), tensor(-14.3923), tensor(-13.7965), tensor(-14.3908), tensor(-14.0770), tensor(-14.3916), tensor(-14.3304), tensor(-14.2694), tensor(-14.2465), tensor(-14.1802), tensor(-13.2785), tensor(-15.2160), tensor(-14.7710), tensor(-14.0642), tensor(-14.2407), tensor(-14.5082), tensor(-15.4111), tensor(-14.6439), tensor(-14.1312), tensor(-14.5301), tensor(-14.5958), tensor(-13.7976), tensor(-14.6266), tensor(-14.8875), tensor(-14.0442), tensor(-15.2420), tensor(-14.8178), tensor(-14.2407), tensor(-14.2786), tensor(-14.8017), tensor(-13.9379), tensor(-14.5469), tensor(-14.1916), tensor(-14.2877), tensor(-13.8821), tensor(-13.3332), tensor(-15.3422), tensor(-13.5600), tensor(-14.4184), tensor(-13.3772), tensor(-13.4759), tensor(-14.1020), tensor(-13.2511), tensor(-15.2143), tensor(-13.8005), tensor(-14.4603), tensor(-14.2274), tensor(-14.5134), tensor(-14.3068), tensor(-14.3775), tensor(-14.0195), tensor(-15.2594), tensor(-14.1932), tensor(-14.2948), tensor(-15.6538), tensor(-14.2872), tensor(-13.9188), tensor(-14.9017), tensor(-14.6249), tensor(-14.0166), tensor(-14.4817), tensor(-14.8461), tensor(-13.2552), tensor(-13.9342), tensor(-14.8315), tensor(-15.3558), tensor(-14.1506), tensor(-14.1712), tensor(-14.0892), tensor(-14.4656), tensor(-13.5839), tensor(-14.8975), tensor(-13.3181), tensor(-14.3774), tensor(-13.8601), tensor(-14.1160), tensor(-14.1444), tensor(-14.6571), tensor(-12.6005), tensor(-15.7517), tensor(-13.5818), tensor(-14.6495), tensor(-15.0624), tensor(-15.0048), tensor(-14.9567), tensor(-13.5997), tensor(-14.6573), tensor(-13.7974), tensor(-14.3094), tensor(-13.4339), tensor(-14.0992), tensor(-13.7000), tensor(-13.4849), tensor(-14.3131), tensor(-15.1040), tensor(-13.9876), tensor(-15.0650), tensor(-14.3304), tensor(-15.8826), tensor(-14.5420), tensor(-14.3260), tensor(-14.9192), tensor(-12.7667), tensor(-14.6399), tensor(-14.2331), tensor(-14.1309), tensor(-14.2249), tensor(-15.0874), tensor(-14.3675), tensor(-13.6647), tensor(-15.0204), tensor(-14.4652), tensor(-14.3235), tensor(-13.9163), tensor(-14.7786), tensor(-13.5603), tensor(-13.8461), tensor(-14.0150), tensor(-14.6772), tensor(-13.4217), tensor(-13.3588), tensor(-15.2041), tensor(-14.6630), tensor(-15.1655), tensor(-15.3525), tensor(-14.1401), tensor(-13.6848), tensor(-14.8185), tensor(-14.0727), tensor(-14.3665), tensor(-14.1600), tensor(-14.9449), tensor(-15.0527), tensor(-14.6333), tensor(-15.2484), tensor(-15.4099), tensor(-13.8707), tensor(-14.7173), tensor(-13.6427), tensor(-14.5632), tensor(-14.3941), tensor(-14.5124), tensor(-13.8043), tensor(-13.5718), tensor(-15.2720), tensor(-14.1340), tensor(-14.3356), tensor(-14.8901), tensor(-14.0405), tensor(-14.4088), tensor(-15.0727), tensor(-13.9609), tensor(-15.0305), tensor(-14.1917), tensor(-14.2726), tensor(-14.6287), tensor(-14.8104), tensor(-14.7873), tensor(-14.2089), tensor(-14.7795), tensor(-14.4952), tensor(-14.0688), tensor(-14.4499), tensor(-14.0221), tensor(-13.3897), tensor(-13.8625), tensor(-14.2565), tensor(-13.9993), tensor(-14.3519), tensor(-14.1362), tensor(-14.9634), tensor(-14.6020), tensor(-13.7720), tensor(-14.6369), tensor(-14.1335), tensor(-14.7201), tensor(-14.7051), tensor(-14.4645), tensor(-14.4369), tensor(-14.0122), tensor(-14.7668), tensor(-13.3802), tensor(-14.1250), tensor(-14.1081), tensor(-14.6793), tensor(-15.2519), tensor(-14.1735), tensor(-13.8789), tensor(-14.1914), tensor(-15.0444), tensor(-13.9230), tensor(-14.0685), tensor(-14.0061), tensor(-14.0869), tensor(-14.1723), tensor(-14.5181), tensor(-13.4820), tensor(-14.3274), tensor(-14.9339), tensor(-14.1008), tensor(-14.5230), tensor(-13.8089), tensor(-13.3108), tensor(-13.9931), tensor(-14.7276), tensor(-14.6201), tensor(-14.0611), tensor(-14.2738), tensor(-14.1282), tensor(-14.1890), tensor(-13.8070), tensor(-14.3645), tensor(-14.4096), tensor(-14.7868), tensor(-14.3656), tensor(-14.1227), tensor(-14.1354), tensor(-14.5608), tensor(-14.0869), tensor(-15.1764), tensor(-14.0552), tensor(-13.1271), tensor(-14.5829), tensor(-14.0998), tensor(-13.4651), tensor(-13.3369), tensor(-13.5796), tensor(-14.5331), tensor(-13.8370), tensor(-14.4220), tensor(-15.3003), tensor(-13.8791), tensor(-14.0940), tensor(-14.4685), tensor(-14.4044), tensor(-14.3902), tensor(-14.6535), tensor(-14.3425), tensor(-14.4996), tensor(-14.4017), tensor(-13.6932), tensor(-14.0876), tensor(-14.6594), tensor(-13.9175), tensor(-14.6477), tensor(-13.4596), tensor(-14.5350), tensor(-14.1571), tensor(-13.6067), tensor(-14.5293), tensor(-14.5455), tensor(-14.1023), tensor(-14.6597), tensor(-13.6531), tensor(-14.7271), tensor(-14.0165), tensor(-14.8889), tensor(-13.9882), tensor(-13.8774), tensor(-12.9808), tensor(-14.1345), tensor(-13.9568), tensor(-14.4380), tensor(-14.9366), tensor(-14.3239), tensor(-14.5753), tensor(-14.2628), tensor(-13.9783), tensor(-15.2259), tensor(-13.8047), tensor(-14.9140), tensor(-14.3911), tensor(-14.4074), tensor(-14.4471), tensor(-14.5459), tensor(-13.9061), tensor(-14.5823), tensor(-14.0410), tensor(-13.8389), tensor(-15.0311), tensor(-13.8971), tensor(-13.5375), tensor(-14.3062), tensor(-14.1249), tensor(-13.7919), tensor(-14.2922), tensor(-14.1867), tensor(-14.2919), tensor(-14.0229), tensor(-14.1499), tensor(-13.2728), tensor(-14.4429), tensor(-14.4820), tensor(-15.8176), tensor(-14.9168), tensor(-14.4962), tensor(-13.4238), tensor(-14.1634), tensor(-12.8647), tensor(-15.0755), tensor(-13.7073), tensor(-13.9311), tensor(-13.5305), tensor(-15.5960), tensor(-15.5819), tensor(-14.5630), tensor(-15.0079), tensor(-14.3430), tensor(-14.2910), tensor(-14.4944), tensor(-14.8545), tensor(-14.0302), tensor(-13.4903), tensor(-13.7642), tensor(-14.3858), tensor(-14.6025), tensor(-13.9304), tensor(-14.7675), tensor(-13.8044), tensor(-13.7460), tensor(-13.9952), tensor(-14.8433), tensor(-14.9662), tensor(-15.2497), tensor(-14.7625), tensor(-14.1975), tensor(-13.8687), tensor(-14.8090), tensor(-14.1604), tensor(-15.2522), tensor(-13.2580), tensor(-15.2501), tensor(-14.7262), tensor(-14.4641), tensor(-13.7234), tensor(-13.6503), tensor(-13.3158), tensor(-14.5291), tensor(-13.6609), tensor(-13.8152), tensor(-14.9897), tensor(-15.4682), tensor(-14.2786), tensor(-14.0914), tensor(-13.9838), tensor(-14.4927), tensor(-14.9028), tensor(-14.5893), tensor(-14.4635), tensor(-14.4448), tensor(-14.1877), tensor(-14.2187), tensor(-14.4830), tensor(-14.3629), tensor(-13.5813), tensor(-14.0585), tensor(-14.8974), tensor(-15.0372), tensor(-15.0132), tensor(-15.3408), tensor(-14.6815), tensor(-14.7937), tensor(-14.3772), tensor(-13.7584), tensor(-13.3030), tensor(-13.8772), tensor(-13.9023), tensor(-13.1359), tensor(-14.5570), tensor(-13.9070), tensor(-14.2064), tensor(-13.9698), tensor(-14.1305), tensor(-14.2911), tensor(-13.0326), tensor(-15.0147), tensor(-13.6186), tensor(-13.3441), tensor(-14.8152), tensor(-14.0582), tensor(-14.1576), tensor(-13.7135), tensor(-13.7153), tensor(-14.5602), tensor(-14.3288), tensor(-13.6494), tensor(-14.4826), tensor(-14.7454), tensor(-14.7206), tensor(-14.0684), tensor(-13.5071), tensor(-14.6204), tensor(-14.2781), tensor(-14.4929), tensor(-14.4800), tensor(-12.9189), tensor(-12.8220), tensor(-14.4231), tensor(-14.0848), tensor(-13.9017), tensor(-15.3914), tensor(-15.1221), tensor(-14.0434), tensor(-14.2839), tensor(-14.8853), tensor(-14.5028), tensor(-14.2574), tensor(-14.1112), tensor(-13.7188), tensor(-14.6257), tensor(-14.4102), tensor(-14.7988), tensor(-14.9836), tensor(-13.6739), tensor(-14.3294), tensor(-14.2226), tensor(-14.4754), tensor(-13.6710), tensor(-13.9141), tensor(-14.4991), tensor(-14.6649), tensor(-13.5534), tensor(-13.8738), tensor(-14.2284), tensor(-13.7946), tensor(-14.7861), tensor(-13.8957), tensor(-15.1219), tensor(-13.7995), tensor(-14.1339), tensor(-13.9172), tensor(-13.4659), tensor(-14.5513), tensor(-14.0242), tensor(-14.5250), tensor(-14.2380), tensor(-14.3365), tensor(-13.9066), tensor(-14.5157), tensor(-14.2739), tensor(-13.8713), tensor(-14.0043), tensor(-14.2868), tensor(-14.4994), tensor(-14.1183), tensor(-13.4935), tensor(-13.9386), tensor(-15.0687), tensor(-14.4185), tensor(-14.6023), tensor(-14.3879), tensor(-13.9676), tensor(-13.9982), tensor(-15.1757), tensor(-14.9119), tensor(-15.1013), tensor(-14.3165), tensor(-14.7802), tensor(-13.6989), tensor(-14.8015), tensor(-13.3335), tensor(-14.0519), tensor(-14.8768), tensor(-15.3938), tensor(-14.1173), tensor(-14.2829), tensor(-14.9477), tensor(-15.1094), tensor(-14.0905), tensor(-15.0936), tensor(-13.0695), tensor(-13.8424), tensor(-13.6219), tensor(-14.5917), tensor(-14.2108), tensor(-14.2603), tensor(-14.9352), tensor(-14.4535), tensor(-14.3490), tensor(-15.2129), tensor(-14.2182), tensor(-13.9620), tensor(-14.7001), tensor(-14.3318), tensor(-14.5921), tensor(-14.5346), tensor(-14.1739), tensor(-15.0619), tensor(-14.2898), tensor(-14.4679), tensor(-14.7286), tensor(-15.1291), tensor(-14.3311), tensor(-14.0541), tensor(-14.0230), tensor(-14.5637), tensor(-14.2928), tensor(-13.4363), tensor(-14.3636), tensor(-14.4096), tensor(-14.1014), tensor(-15.0943), tensor(-14.4412), tensor(-13.8086), tensor(-14.6288), tensor(-14.4885), tensor(-13.3732), tensor(-14.0465), tensor(-14.0580), tensor(-15.0186), tensor(-13.6978), tensor(-13.5638), tensor(-13.7293), tensor(-14.9169), tensor(-14.9264), tensor(-15.4207), tensor(-14.1358), tensor(-14.1798), tensor(-14.8321), tensor(-14.3650), tensor(-14.7779), tensor(-13.5848), tensor(-13.2832), tensor(-14.1592), tensor(-14.1345), tensor(-13.8917), tensor(-15.5617), tensor(-14.1917), tensor(-14.2749), tensor(-13.9853), tensor(-14.2388), tensor(-14.6651), tensor(-14.8366), tensor(-15.6540), tensor(-14.9144), tensor(-13.9245), tensor(-13.9815), tensor(-14.6328), tensor(-13.7906), tensor(-13.8999), tensor(-14.1753), tensor(-14.0101), tensor(-12.7525), tensor(-14.3524), tensor(-12.8015), tensor(-13.6826), tensor(-14.4320), tensor(-14.0426), tensor(-13.3403), tensor(-14.3963), tensor(-14.4119), tensor(-14.0343), tensor(-13.6358), tensor(-14.1103), tensor(-13.9029), tensor(-14.0812), tensor(-14.3526), tensor(-15.8678), tensor(-13.8911), tensor(-14.3957), tensor(-14.2963), tensor(-14.5345), tensor(-14.4479), tensor(-15.8677), tensor(-14.2903), tensor(-13.6322), tensor(-14.0936), tensor(-14.2583), tensor(-13.8985), tensor(-14.2882), tensor(-13.3054), tensor(-14.1528), tensor(-14.8217), tensor(-14.2382), tensor(-13.1692), tensor(-14.1024), tensor(-14.2218), tensor(-14.2131), tensor(-13.9273), tensor(-13.6400), tensor(-15.2043), tensor(-14.5575), tensor(-14.5070), tensor(-15.8197), tensor(-14.4527), tensor(-13.8681), tensor(-14.4062), tensor(-14.6213), tensor(-15.0008), tensor(-14.9843), tensor(-15.1920), tensor(-14.3845), tensor(-14.0282), tensor(-14.9430), tensor(-14.4918), tensor(-14.2481), tensor(-14.6754), tensor(-13.2047), tensor(-14.7543), tensor(-13.7533), tensor(-14.0381), tensor(-13.6247), tensor(-14.2334), tensor(-13.8244), tensor(-13.5761), tensor(-14.6025), tensor(-14.5126), tensor(-14.8819), tensor(-13.8749), tensor(-13.9232), tensor(-14.7544), tensor(-14.7428), tensor(-13.9771), tensor(-15.6903), tensor(-14.1725), tensor(-13.9252), tensor(-14.6163), tensor(-14.7364), tensor(-14.0743), tensor(-14.3185), tensor(-14.2960), tensor(-13.8695), tensor(-13.7737), tensor(-14.8389), tensor(-14.9531), tensor(-13.8893), tensor(-15.1862), tensor(-13.9211), tensor(-13.9730), tensor(-14.0181), tensor(-14.3895), tensor(-14.6102), tensor(-15.0140), tensor(-14.7409), tensor(-14.9704), tensor(-14.0545), tensor(-14.2438), tensor(-13.7072), tensor(-14.0741), tensor(-14.3465), tensor(-14.8434), tensor(-14.9554), tensor(-13.8147), tensor(-14.0454), tensor(-13.6870), tensor(-14.0476), tensor(-13.0381), tensor(-15.2349), tensor(-13.1179), tensor(-15.0497), tensor(-13.9111), tensor(-14.4774), tensor(-13.7425), tensor(-14.3134), tensor(-15.4779), tensor(-13.5607), tensor(-14.6143), tensor(-14.1076), tensor(-14.0828), tensor(-14.0459), tensor(-14.2988), tensor(-14.9784), tensor(-14.3264), tensor(-13.7081), tensor(-13.6985), tensor(-14.5184), tensor(-13.9778), tensor(-14.7969), tensor(-14.2091), tensor(-14.5786), tensor(-13.4748), tensor(-13.9887), tensor(-14.5882), tensor(-14.2679), tensor(-14.1161), tensor(-14.5955), tensor(-14.4670), tensor(-13.8877), tensor(-13.7825), tensor(-15.1797), tensor(-15.0229), tensor(-15.1528)]\n",
      "45000\n",
      "44995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 157/157 [00:06<00:00, 22.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.3038, Accuracy: 0.5425, F1 Score: 0.5327\n",
      "Epoch 1/2 - Train Loss: 1.0464, Val Loss: 1.3038, Acc: 0.5425, F1: 0.5327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 79/79 [00:05<00:00, 13.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(-14.8107), tensor(-15.1199), tensor(-14.4863), tensor(-13.8317), tensor(-14.8667), tensor(-14.4588), tensor(-15.1447), tensor(-14.4861), tensor(-15.0273), tensor(-15.0570), tensor(-14.3123), tensor(-14.1142), tensor(-14.1187), tensor(-15.3073), tensor(-14.1111), tensor(-14.3584), tensor(-14.7774), tensor(-14.7364), tensor(-13.1282), tensor(-14.7112), tensor(-15.1688), tensor(-14.3176), tensor(-14.2650), tensor(-13.9763), tensor(-13.7741), tensor(-14.2896), tensor(-15.2843), tensor(-14.0473), tensor(-14.3878), tensor(-14.2902), tensor(-13.7745), tensor(-14.8722), tensor(-14.1277), tensor(-13.9393), tensor(-14.5727), tensor(-15.0498), tensor(-14.4147), tensor(-13.9490), tensor(-14.4789), tensor(-13.8333), tensor(-14.4014), tensor(-14.0738), tensor(-14.2900), tensor(-14.5123), tensor(-14.2212), tensor(-14.3049), tensor(-14.2302), tensor(-14.6350), tensor(-14.2610), tensor(-14.8602), tensor(-14.4360), tensor(-14.2967), tensor(-15.0408), tensor(-14.1543), tensor(-13.9970), tensor(-14.5947), tensor(-15.1462), tensor(-14.9771), tensor(-14.2376), tensor(-14.4795), tensor(-13.8483), tensor(-14.3819), tensor(-14.6298), tensor(-14.9373), tensor(-15.3441), tensor(-14.2964), tensor(-15.7571), tensor(-13.9346), tensor(-13.4181), tensor(-14.6809), tensor(-14.8409), tensor(-14.2918), tensor(-14.3456), tensor(-15.1927), tensor(-14.6803), tensor(-14.4952), tensor(-14.6456), tensor(-14.0562), tensor(-14.2741), tensor(-14.3211), tensor(-14.7137), tensor(-14.8088), tensor(-15.2922), tensor(-14.3298), tensor(-15.3931), tensor(-14.3532), tensor(-13.4445), tensor(-14.1064), tensor(-14.3283), tensor(-14.4201), tensor(-14.6916), tensor(-14.9425), tensor(-14.7670), tensor(-14.5941), tensor(-14.6148), tensor(-14.4659), tensor(-14.2869), tensor(-14.4006), tensor(-14.0915), tensor(-14.3391), tensor(-14.4935), tensor(-14.1968), tensor(-13.5740), tensor(-15.5539), tensor(-14.2096), tensor(-14.0593), tensor(-14.3835), tensor(-14.5288), tensor(-14.5226), tensor(-15.1088), tensor(-13.8112), tensor(-13.4345), tensor(-14.6130), tensor(-14.3607), tensor(-13.6924), tensor(-13.3697), tensor(-14.3239), tensor(-14.7328), tensor(-15.3440), tensor(-14.6172), tensor(-14.0235), tensor(-14.8955), tensor(-14.0792), tensor(-14.4605), tensor(-14.8923), tensor(-14.1376), tensor(-14.9467), tensor(-14.5694), tensor(-14.6508), tensor(-14.9380), tensor(-14.2549), tensor(-14.1217), tensor(-14.4311), tensor(-14.0767), tensor(-14.8887), tensor(-13.8121), tensor(-14.5797), tensor(-14.2376), tensor(-14.4024), tensor(-14.4438), tensor(-14.4017), tensor(-13.7928), tensor(-14.7615), tensor(-14.0955), tensor(-13.6212), tensor(-14.6304), tensor(-14.3306), tensor(-13.7350), tensor(-14.4012), tensor(-13.5822), tensor(-14.1290), tensor(-14.5021), tensor(-14.1690), tensor(-15.2915), tensor(-14.8201), tensor(-14.3288), tensor(-14.3463), tensor(-15.4078), tensor(-14.6398), tensor(-14.8803), tensor(-14.1186), tensor(-13.3615), tensor(-14.1153), tensor(-14.8050), tensor(-14.7075), tensor(-14.4257), tensor(-14.9983), tensor(-14.1708), tensor(-14.2497), tensor(-13.6857), tensor(-13.8097), tensor(-13.6399), tensor(-14.7115), tensor(-14.4408), tensor(-15.0977), tensor(-14.4643), tensor(-13.5006), tensor(-14.8488), tensor(-14.5973), tensor(-14.8122), tensor(-14.7768), tensor(-14.5748), tensor(-14.8680), tensor(-14.6753), tensor(-13.8407), tensor(-14.7290), tensor(-14.3882), tensor(-14.3021), tensor(-13.8545), tensor(-15.3191), tensor(-14.3266), tensor(-13.6334), tensor(-14.1580), tensor(-13.7270), tensor(-14.1999), tensor(-13.5926), tensor(-14.5203), tensor(-14.5162), tensor(-15.0787), tensor(-13.6348), tensor(-14.7405), tensor(-14.5116), tensor(-14.4447), tensor(-13.0169), tensor(-14.5382), tensor(-14.5583), tensor(-14.8924), tensor(-14.4876), tensor(-14.7337), tensor(-13.8265), tensor(-14.4583), tensor(-14.0412), tensor(-15.1176), tensor(-15.1952), tensor(-15.4297), tensor(-14.1189), tensor(-14.7161), tensor(-13.6846), tensor(-13.6494), tensor(-14.5170), tensor(-14.6720), tensor(-14.0362), tensor(-14.7072), tensor(-13.5767), tensor(-13.6778), tensor(-13.6734), tensor(-14.9611), tensor(-14.7789), tensor(-14.3111), tensor(-14.6338), tensor(-13.6969), tensor(-14.7863), tensor(-14.8406), tensor(-14.4515), tensor(-14.7805), tensor(-15.3091), tensor(-14.5265), tensor(-14.0702), tensor(-14.3250), tensor(-14.6786), tensor(-14.1903), tensor(-14.7719), tensor(-14.6447), tensor(-13.9814), tensor(-14.4275), tensor(-13.2197), tensor(-14.5579), tensor(-14.5259), tensor(-14.2841), tensor(-14.7013), tensor(-15.1880), tensor(-14.3338), tensor(-14.9203), tensor(-14.6618), tensor(-14.1485), tensor(-14.0115), tensor(-13.8902), tensor(-14.4023), tensor(-14.3525), tensor(-13.6137), tensor(-14.7336), tensor(-14.2725), tensor(-13.6928), tensor(-14.8376), tensor(-14.3929), tensor(-14.2844), tensor(-14.6835), tensor(-13.8381), tensor(-14.5486), tensor(-13.6163), tensor(-14.3749), tensor(-13.9057), tensor(-14.2517), tensor(-15.0555), tensor(-14.7554), tensor(-14.0639), tensor(-14.9944), tensor(-14.4934), tensor(-14.0448), tensor(-14.5036), tensor(-15.4405), tensor(-13.6457), tensor(-14.3148), tensor(-14.4644), tensor(-14.2163), tensor(-14.4466), tensor(-14.2823), tensor(-13.6389), tensor(-14.9912), tensor(-13.5891), tensor(-14.2586), tensor(-14.1482), tensor(-13.9974), tensor(-15.1072), tensor(-14.0465), tensor(-14.1008), tensor(-14.0434), tensor(-14.4514), tensor(-13.9019), tensor(-14.6835), tensor(-14.3916), tensor(-14.5819), tensor(-14.0530), tensor(-14.8305), tensor(-14.5316), tensor(-13.6005), tensor(-13.5630), tensor(-14.6903), tensor(-15.0197), tensor(-13.9383), tensor(-14.4637), tensor(-14.0942), tensor(-14.3545), tensor(-14.4590), tensor(-14.0048), tensor(-14.0897), tensor(-14.9276), tensor(-14.3923), tensor(-14.9029), tensor(-14.2150), tensor(-14.3571), tensor(-14.1993), tensor(-13.9622), tensor(-15.9451), tensor(-14.8197), tensor(-14.1995), tensor(-13.9234), tensor(-14.8407), tensor(-14.4898), tensor(-15.2079), tensor(-13.7471), tensor(-14.0187), tensor(-14.1950), tensor(-14.3012), tensor(-14.6665), tensor(-14.1731), tensor(-14.4598), tensor(-13.5426), tensor(-14.6236), tensor(-14.7311), tensor(-14.6569), tensor(-14.1324), tensor(-14.1112), tensor(-14.4608), tensor(-14.3160), tensor(-14.3112), tensor(-14.6299), tensor(-14.6237), tensor(-14.2172), tensor(-14.3902), tensor(-14.0276), tensor(-14.4524), tensor(-13.8472), tensor(-14.9632), tensor(-14.3762), tensor(-14.0087), tensor(-14.8635), tensor(-15.0640), tensor(-14.6546), tensor(-14.2429), tensor(-14.5762), tensor(-15.0965), tensor(-14.2102), tensor(-13.9091), tensor(-13.9198), tensor(-13.7774), tensor(-15.2011), tensor(-15.4353), tensor(-14.7780), tensor(-13.9456), tensor(-14.7935), tensor(-15.0113), tensor(-13.6725), tensor(-14.3394), tensor(-13.8927), tensor(-14.0909), tensor(-14.0390), tensor(-14.6149), tensor(-14.8006), tensor(-15.1707), tensor(-13.7550), tensor(-14.4225), tensor(-14.2545), tensor(-13.5120), tensor(-14.3010), tensor(-14.6626), tensor(-14.3722), tensor(-14.5668), tensor(-14.9777), tensor(-14.3411), tensor(-13.9383), tensor(-14.3909), tensor(-13.6135), tensor(-14.7221), tensor(-14.9489), tensor(-15.4439), tensor(-14.3324), tensor(-14.4935), tensor(-14.2874), tensor(-14.5463), tensor(-13.7211), tensor(-14.4803), tensor(-14.6056), tensor(-14.4867), tensor(-15.8627), tensor(-14.7725), tensor(-15.1073), tensor(-14.6733), tensor(-13.7868), tensor(-14.2218), tensor(-15.0630), tensor(-15.0066), tensor(-13.9538), tensor(-14.1285), tensor(-14.1131), tensor(-14.2231), tensor(-14.0459), tensor(-14.8194), tensor(-14.0980), tensor(-14.8275), tensor(-13.6201), tensor(-14.9816), tensor(-13.1273), tensor(-14.3356), tensor(-15.2220), tensor(-13.8894), tensor(-14.8370), tensor(-14.0488), tensor(-14.0229), tensor(-14.3896), tensor(-14.1146), tensor(-13.9577), tensor(-13.9847), tensor(-13.8316), tensor(-13.7509), tensor(-14.0715), tensor(-15.2026), tensor(-15.0490), tensor(-14.3588), tensor(-14.6381), tensor(-13.9069), tensor(-14.8935), tensor(-13.9754), tensor(-14.9338), tensor(-14.3840), tensor(-14.1649), tensor(-14.5015), tensor(-14.5725), tensor(-14.3281), tensor(-14.7972), tensor(-15.0862), tensor(-14.4177), tensor(-14.3997), tensor(-13.5884), tensor(-14.5725), tensor(-13.5623), tensor(-14.4339), tensor(-14.8923), tensor(-14.4847), tensor(-14.3608), tensor(-14.6194), tensor(-14.2980), tensor(-14.5094), tensor(-13.7453), tensor(-13.3255), tensor(-14.2108), tensor(-13.9238), tensor(-14.0318), tensor(-14.0154), tensor(-14.6254), tensor(-14.5139), tensor(-14.3655), tensor(-14.4295), tensor(-14.1010), tensor(-14.4710), tensor(-14.2456), tensor(-14.0494), tensor(-14.1914), tensor(-15.1421), tensor(-13.7113), tensor(-14.4041), tensor(-15.1105), tensor(-14.5631), tensor(-14.0281), tensor(-14.3644), tensor(-14.9180), tensor(-15.3639), tensor(-14.1234), tensor(-14.2010), tensor(-14.6940), tensor(-14.7356), tensor(-14.8928), tensor(-14.1262), tensor(-14.1685), tensor(-14.1206), tensor(-13.8134), tensor(-13.7629), tensor(-14.2371), tensor(-14.8786), tensor(-14.8798), tensor(-14.4810), tensor(-14.3296), tensor(-15.1700), tensor(-14.6263), tensor(-14.3587), tensor(-14.0116), tensor(-14.7698), tensor(-15.0910), tensor(-14.3939), tensor(-14.6978), tensor(-14.8812), tensor(-14.3821), tensor(-15.2251), tensor(-13.5475), tensor(-14.6690), tensor(-15.1418), tensor(-14.3317), tensor(-13.6899), tensor(-15.2162), tensor(-15.3128), tensor(-14.3966), tensor(-14.3198), tensor(-14.0893), tensor(-14.9524), tensor(-14.5320), tensor(-14.3526), tensor(-14.6497), tensor(-14.1037), tensor(-14.1381), tensor(-14.5809), tensor(-13.8086), tensor(-13.8203), tensor(-14.3457), tensor(-13.7279), tensor(-15.1009), tensor(-14.2547), tensor(-13.7453), tensor(-14.5381), tensor(-15.6071), tensor(-14.5289), tensor(-14.5492), tensor(-14.4573), tensor(-13.9001), tensor(-14.2001), tensor(-14.2541), tensor(-13.6726), tensor(-14.9615), tensor(-14.4247), tensor(-14.6785), tensor(-14.4649), tensor(-14.8997), tensor(-14.0833), tensor(-14.2974), tensor(-14.4863), tensor(-14.7072), tensor(-14.4993), tensor(-14.1839), tensor(-14.5143), tensor(-15.2989), tensor(-13.6365), tensor(-14.7758), tensor(-14.6098), tensor(-14.6273), tensor(-14.7212), tensor(-14.2399), tensor(-15.1148), tensor(-14.3728), tensor(-14.3505), tensor(-14.5343), tensor(-14.1263), tensor(-15.1082), tensor(-15.0407), tensor(-14.5055), tensor(-14.1365), tensor(-13.7996), tensor(-14.6357), tensor(-14.2536), tensor(-15.2647), tensor(-13.8900), tensor(-13.8378), tensor(-14.7083), tensor(-13.7707), tensor(-13.9612), tensor(-13.9749), tensor(-14.7872), tensor(-14.9864), tensor(-14.6937), tensor(-14.9625), tensor(-15.0742), tensor(-14.7417), tensor(-14.9222), tensor(-14.5267), tensor(-14.3293), tensor(-14.6536), tensor(-14.6384), tensor(-13.9758), tensor(-13.6205), tensor(-14.4637), tensor(-14.6692), tensor(-14.5218), tensor(-14.1729), tensor(-13.8499), tensor(-14.1425), tensor(-14.4893), tensor(-13.7694), tensor(-13.6808), tensor(-15.0119), tensor(-14.3253), tensor(-15.5838), tensor(-14.3282), tensor(-13.9778), tensor(-14.0649), tensor(-14.4135), tensor(-15.3072), tensor(-13.5033), tensor(-13.9332), tensor(-14.6802), tensor(-14.0584), tensor(-14.4856), tensor(-14.1573), tensor(-13.6749), tensor(-14.5420), tensor(-14.8670), tensor(-14.5635), tensor(-14.3299), tensor(-14.3707), tensor(-15.2873), tensor(-14.6317), tensor(-13.7077), tensor(-14.0035), tensor(-13.7385), tensor(-14.2902), tensor(-14.9687), tensor(-14.6636), tensor(-14.5861), tensor(-13.9216), tensor(-14.2953), tensor(-14.4018), tensor(-14.3284), tensor(-15.0051), tensor(-14.7591), tensor(-14.1834), tensor(-14.9675), tensor(-14.1578), tensor(-14.0128), tensor(-14.3978), tensor(-14.7067), tensor(-15.3775), tensor(-15.8281), tensor(-14.6353), tensor(-14.5345), tensor(-14.5705), tensor(-15.2916), tensor(-14.4901), tensor(-15.1729), tensor(-14.1379), tensor(-14.3446), tensor(-14.1642), tensor(-14.8952), tensor(-14.1028), tensor(-15.7087), tensor(-14.6390), tensor(-14.8896), tensor(-14.1694), tensor(-14.1226), tensor(-14.8066), tensor(-14.4516), tensor(-13.8180), tensor(-14.7642), tensor(-14.4485), tensor(-14.0169), tensor(-14.7264), tensor(-14.1196), tensor(-14.4170), tensor(-14.9617), tensor(-15.3101), tensor(-13.5441), tensor(-13.9571), tensor(-14.8858), tensor(-14.6204), tensor(-15.0974), tensor(-13.6139), tensor(-14.6177), tensor(-14.3342), tensor(-13.4727), tensor(-15.0267), tensor(-14.6530), tensor(-14.1763), tensor(-13.9342), tensor(-14.0900), tensor(-14.5482), tensor(-14.8197), tensor(-14.1530), tensor(-14.4245), tensor(-14.3876), tensor(-13.7671), tensor(-14.2396), tensor(-14.7586), tensor(-13.3235), tensor(-13.4624), tensor(-14.6608), tensor(-14.3481), tensor(-13.5293), tensor(-15.4975)]\n",
      "44995\n",
      "44988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 157/157 [00:06<00:00, 22.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.2370, Accuracy: 0.5561, F1 Score: 0.5571\n",
      "Epoch 2/2 - Train Loss: 1.0056, Val Loss: 1.2370, Acc: 0.5561, F1: 0.5571\n"
     ]
    }
   ],
   "source": [
    "train.fit(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc941e93-7495-4e80-8f7a-831462890964",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
